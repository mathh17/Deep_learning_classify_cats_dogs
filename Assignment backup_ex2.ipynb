{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-90b57f3b471e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_img\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "# load and display an image with Matplotlib\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from numpy import asarray\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Getting the data in\n",
    "\n",
    "# ift. opdelingen af test,train og validering har jeg simpelthen bare taget det manuelt fra den store mappe og opdelt det i 20% test og 20% af train til validering\n",
    "# Dette betyder at vi fra det originale data har:\n",
    "# test: 520 billeder, 260 af hver\n",
    "# train: 1664 billeder, 832 af hver\n",
    "# Validation: 416, 206 af hver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through the folder containing the data and adds them to a list, generates labels and add data to validate labels against\n",
    "\n",
    "def load_image_function(path):\n",
    "\n",
    "    images = [] # empty list placeholder\n",
    "    labels = [] # empty list placeholder\n",
    "    animal_checker = 'cat' # used to create labels\n",
    "    container = [] # container to validate correct labels\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "\n",
    "      container.append(filename) # add filename to container\n",
    "\n",
    "      if animal_checker in filename:\n",
    "        labels.append('cat') # check if cat is in filename. If so append cat to label\n",
    "      elif animal_checker not in filename:\n",
    "        labels.append('dog') # else add dog to label\n",
    "\n",
    "      animal_photo = load_img(path + f'/{filename}', target_size = (150, 150)) # standardize photo size + loads\n",
    "      animal_photo = img_to_array(animal_photo) # creates an array\n",
    "\n",
    "      images.append(animal_photo) # append the photo to the images. The images list contains a list of arrays\n",
    "    \n",
    "    return asarray(images), asarray(labels), container; # not interested in list of arrays, but array containing lists. Asarray does this. Returns three arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, train_container = load_image_function('./train') # load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training labels is: ['cat' 'cat' 'cat' 'cat' 'cat'] and the imported is ['cat.1500.jpg', 'cat.1501.jpg', 'cat.1502.jpg', 'cat.1503.jpg', 'cat.1504.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(f'The training labels is: {train_labels[:5]} and the imported is {train_container[:5]}') # check train data is correct loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test labels is: ['cat' 'cat' 'cat' 'cat' 'cat'] and the imported is ['cat.0.jpg', 'cat.1.jpg', 'cat.10.jpg', 'cat.100.jpg', 'cat.101.jpg']\n"
     ]
    }
   ],
   "source": [
    "test_data, test_labels, test_container = load_image_function('./test') # load test data\n",
    "\n",
    "print(f'The test labels is: {test_labels[:5]} and the imported is {test_container[:5]}') # check test data is correct loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The val labels is: ['cat' 'cat' 'cat' 'cat' 'cat'] and the imported is ['cat.230.jpg', 'cat.231.jpg', 'cat.232.jpg', 'cat.233.jpg', 'cat.234.jpg']\n"
     ]
    }
   ],
   "source": [
    "val_data, val_labels, val_container = load_image_function('./validation') # load val data\n",
    "\n",
    "print(f'The val labels is: {val_labels[:5]} and the imported is {val_container[:5]}') # check val data is correct loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train has shape: (1664, 150, 150, 3) \n",
      "Test has shape: (520, 150, 150, 3) \n",
      "Validation has shape: (416, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "# checking if reshape is necessary. \n",
    "\n",
    "print(f'Train has shape: {train_data.shape} \\nTest has shape: {test_data.shape} \\nValidation has shape: {val_data.shape}')\n",
    "\n",
    "# Since they all have (# rows, width, height, # of color channelse) reshaping is not necessary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Create the datagenerators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high amount of data, you need to write a datagenerator to load the images. This requires you to use the _ImageDataGenerator_ (as shown in Keras Intro - 2) in which you must apply at least one on-the-fly data augmentation. Which type of data augmentation is up to you, but you need to justify your choice in your report. On top of the _ImagaDataGenerator_ you need to apply the _.flow_from_directory_ function to make it work with the directory tree in Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to use (at least) one on-the-fly augmentation. Which is better to use? Zooming, flipping, shifting, changing brightness? Should we use more than one? \n",
    "\n",
    "ImageDataGenerator: \n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "flow_from_directory: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\45306\\\\Documents\\\\GitHub\\\\Deep_learning_Data'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Data Generator -- (From Intro to Keras 2, the default settings)\n",
    "data_gen = ImageDataGenerator(\n",
    "        featurewise_center=False, samplewise_center=False,\n",
    "        featurewise_std_normalization=False, samplewise_std_normalization=False,\n",
    "        zca_whitening=False, zca_epsilon=1e-06, rotation_range=0, width_shift_range=0.0,\n",
    "        height_shift_range=0.0, brightness_range=None, shear_range=0.0, zoom_range=0.0,\n",
    "        channel_shift_range=0.0, fill_mode='nearest', cval=0.0,\n",
    "        horizontal_flip=False, vertical_flip=False, rescale=None,\n",
    "        preprocessing_function=None, data_format=None, validation_split=0.0, dtype=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from this site: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html \n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from the same site. Here, we only take one image, and puts it in the \"preview\"-directory, which I have made manually. \n",
    "# Problem: It does not delete the pictures when running the chunk again. \n",
    "img = load_img('Train/cat.871.jpg')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='preview', save_prefix='cat', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
